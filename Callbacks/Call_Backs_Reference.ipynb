{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5G7ugMJtOMWw"
   },
   "source": [
    "<h1> <font color='red'> DO read all the comments in the python code and contents in the markdown cells</font> </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KNLBT5GUbQUN"
   },
   "source": [
    "<pre><font size=4><b>\n",
    "You can do this assignment in google colab itself. we have provided a notebook to use tensorboard in google colab itself.</b></font>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gjzTYtr1OMW3"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#enabled to get instant output. if you don't need, you can use session concept which was dicussed in lecture videos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "3rOqYAusgIhU",
    "outputId": "d0df2b7e-4cd8-4307-f936-4c141aa35fe7"
   },
   "outputs": [],
   "source": [
    "a = tf.random.uniform(shape=(1000,8,1,64))\n",
    "b = tf.random.uniform(shape=(1000,8,1,64))\n",
    "add =tf.concat([a,b],2)\n",
    "print(add.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K0WP3DUvOMW_"
   },
   "source": [
    "## 1.1 Addition\n",
    "<pre> It is similar to numpy addition.</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "id": "qcKl2W9qOMXC",
    "outputId": "36f8bb88-cd28-4335-a2df-93a31d1619de"
   },
   "outputs": [],
   "source": [
    "a = tf.random.uniform(shape=(2,2))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "id": "COUVYv5BOMXO",
    "outputId": "de776902-5791-49b3-9840-87965d472f41"
   },
   "outputs": [],
   "source": [
    "b = tf.random.uniform(shape=(2,2))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7I1KMCgiOMXV"
   },
   "outputs": [],
   "source": [
    "add = a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "id": "ksQu6lT6OMXa",
    "outputId": "27692d8c-a490-426f-a321-7d0b4396b4b7"
   },
   "outputs": [],
   "source": [
    "add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPxWE4stOMXe"
   },
   "source": [
    "<pre>Broadcasting works similar to numpy.</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kKaICOghOMXg"
   },
   "outputs": [],
   "source": [
    "c = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7pINN69LOMXn"
   },
   "outputs": [],
   "source": [
    "add_2 = a + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LIaJTqAwOMXr",
    "outputId": "c510312e-78e7-45d0-d40d-52780d62b18c"
   },
   "outputs": [],
   "source": [
    "add_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1rOJ8iYoOMXw"
   },
   "source": [
    "## 1.2 Subtraction\n",
    "<pre> It is similar to numpy Subtraction.</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x8o22IU7OMXy",
    "outputId": "9bfb179f-8fad-4ef5-cdc6-7b918e37ac6e"
   },
   "outputs": [],
   "source": [
    "a = tf.random.uniform(shape=(2,2))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IUEmz0MKOMX5",
    "outputId": "87012331-692b-4218-d7ff-33b2d97c0a1f"
   },
   "outputs": [],
   "source": [
    "b = tf.random.uniform(shape=(2,2))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vlGlc6CZOMX8"
   },
   "outputs": [],
   "source": [
    "sub = a - b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mEst3O84OMYB",
    "outputId": "36456888-3567-4e6e-df04-9cc606fd3b63"
   },
   "outputs": [],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0fjRvsmIOMYG"
   },
   "source": [
    "## 1.3 Multiplication\n",
    "<pre>\n",
    "- For two dimensional matrices, you can multiply (m*n) and (n*p) and get (m*p)\n",
    "- for 3 dim matrices, you can multiply (b * n * p)  and (b * p * m)  and get (b * n * m). ( for any dim, you have to maintain last 2 dim as two dim multiplication and first n-2 dim has to be same. you will get better idea if you gothrough    all the operation which we have written below.)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OwTNd9c9OMYI",
    "outputId": "b7b2476c-db99-405d-e6f9-b09d9680adc7"
   },
   "outputs": [],
   "source": [
    "a = tf.random.uniform(shape=(3,2))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Z3SOY-9OMYL",
    "outputId": "3a2c4ef2-bf07-44d3-dda3-0d51c21aee48"
   },
   "outputs": [],
   "source": [
    "b = tf.random.uniform(shape=(2,4))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4PKZKq6COMYP",
    "outputId": "858e7e21-e17e-486d-8089-d56ac69f356f"
   },
   "outputs": [],
   "source": [
    "tf.matmul(a, b)# (3*2)@(2*4) = (3*4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYtPMQCFOMYV"
   },
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qx21Dbw3OMYY"
   },
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SKVwmcKROMYY",
    "outputId": "91d8271f-1792-4f19-8997-785831f47032"
   },
   "outputs": [],
   "source": [
    "a = tf.random.uniform(shape=(3,2,4))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mzkP827ROMYd",
    "outputId": "f4982e2e-0f8b-4a2a-f552-b5bc5797e5e7"
   },
   "outputs": [],
   "source": [
    "b = tf.random.uniform(shape=(3,4,3))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5czLohlFOMYg",
    "outputId": "c786fe34-52f4-471d-fe02-dff13776af91"
   },
   "outputs": [],
   "source": [
    "tf.matmul(a, b) #(3*2*4)@(3*4*3) = (3*2*3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XYmcWP5fOMYj"
   },
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WzrmujBNOMYm"
   },
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c8OvUeISOMYp",
    "outputId": "ba7ecb53-eaf5-4661-e773-afa56b29fc21"
   },
   "outputs": [],
   "source": [
    "a = tf.random.uniform(shape=(3,2,2,4))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ap6ISJUTOMYs",
    "outputId": "85582bc7-53e7-4469-ba90-f8620c723c15"
   },
   "outputs": [],
   "source": [
    "b = tf.random.uniform(shape=(3,2,4,3))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gyzlUiPuOMYv",
    "outputId": "6398669a-01d9-4d1a-819f-4c1ea453d852"
   },
   "outputs": [],
   "source": [
    "tf.matmul(a,b) # (3*2*2*4)@(3*2*4*3)=(3*2*2*3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vhFWsCP1OMY0"
   },
   "source": [
    "## 1. 4 Transpose\n",
    "<pre>    - matrix transpose. </pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "chFxqDYUOMY0",
    "outputId": "8f695cd4-a9fa-4e36-9775-6f13dad25ac1"
   },
   "outputs": [],
   "source": [
    "a = tf.random.uniform(shape=(3,2))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hcgW9_ctOMY5",
    "outputId": "7cee185b-054f-4300-d5b9-48b9665ce266"
   },
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2qoOVv8pOMY9",
    "outputId": "9e01e07a-026e-499e-ac90-781bd8edd78e"
   },
   "outputs": [],
   "source": [
    "tf.transpose(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BwTCIpAQOMZA"
   },
   "source": [
    "<pre>We have a \"perm\" argument for transpose function, in that you can define your own way to change rows and column positions. as shown below</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iMyw2YIAOMZB",
    "outputId": "62093672-34a0-4f2d-a0db-3c7648ec3485"
   },
   "outputs": [],
   "source": [
    "a = tf.random.uniform(shape=(3,2,5,4))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GUquLpjJOMZG"
   },
   "outputs": [],
   "source": [
    "a_transpose = tf.transpose(a, perm=[0, 2, 1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4K7g_bAsOMZK",
    "outputId": "ef86f009-d814-4b24-cc5b-abee06aa420a"
   },
   "outputs": [],
   "source": [
    "a_transpose.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zmDQktLGOMZO"
   },
   "source": [
    "<pre>My transposed matrix dim changed based on pem values( we transposed 1 and 2 axis only). you can check below example in that we chnaged all the axis</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pD1ytjz0OMZP",
    "outputId": "b2acaecd-9ef3-4263-9eca-c8f91958cbfe"
   },
   "outputs": [],
   "source": [
    "a = tf.random.uniform(shape=(3,2,5,4))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IagVMwNjOMZR"
   },
   "outputs": [],
   "source": [
    "a_transpose = tf.transpose(a, perm=[3, 2, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rbcCTZuiOMZU",
    "outputId": "9d0c0432-706c-4b04-c0bb-fab83d6192ff"
   },
   "outputs": [],
   "source": [
    "a_transpose.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_galZ10JOMZX"
   },
   "source": [
    "## 1. 4 Element wise operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "luaCDJ_8OMZY"
   },
   "source": [
    "### 1.4.1 Multiply Respective elements in two matrices\n",
    "Ex: \n",
    "<pre>\n",
    "A = [[1 2],\n",
    "     [3,4]]\n",
    "\n",
    "B = [[5,6],\n",
    "     [7,8]]\n",
    "\n",
    "we want A*B as \n",
    "[A[0][0]*B[0][0], A[0][1]*B[0][1]\n",
    "A[1][0]*B[1][0], A[1][1]*B[1][1]]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rIOB8zyIOMZZ",
    "outputId": "3ec7c53e-9347-4950-8359-443895d507b8"
   },
   "outputs": [],
   "source": [
    "a = tf.random.uniform(shape=(3,2))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kJxr1BFgOMZc",
    "outputId": "f1404940-d2f2-4f8e-d887-6863e9112890"
   },
   "outputs": [],
   "source": [
    "b = tf.random.uniform(shape=(3,2))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qszNHNK8OMZe",
    "outputId": "b2cf32a9-29dd-485b-e845-b8e1e788324a"
   },
   "outputs": [],
   "source": [
    "a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PLWk8lQkOMZg",
    "outputId": "7e4d4b95-e10e-48a2-e123-5ac3b5ada568"
   },
   "outputs": [],
   "source": [
    "tf.multiply(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k6KnJSQ9OMZi"
   },
   "source": [
    "<pre>You can do a*b or you can use tf.multiply</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z8dLCOEaOMZj"
   },
   "source": [
    "## 1.5 Expanding Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GrSkSucPOMZj",
    "outputId": "66be7e9f-b2d9-4045-9b1f-a85e35d3cd1a"
   },
   "outputs": [],
   "source": [
    "a = tf.random.uniform(shape=(3,2))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ea9KHLbSOMZm"
   },
   "outputs": [],
   "source": [
    "a_add = tf.expand_dims(a, axis=1)#we are adding an additional axis at 1st dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YfcxwikXOMZq",
    "outputId": "b735dccc-a254-47b9-9ee0-c0077237deb9"
   },
   "outputs": [],
   "source": [
    "a_add.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16tS1mknOMZu"
   },
   "source": [
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t28TsjlQOMZv"
   },
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2q_MkdrgOMZw",
    "outputId": "dd3d6bd9-8bd4-441e-c51e-8a4d0432770c"
   },
   "outputs": [],
   "source": [
    "a = tf.random.uniform(shape=(3,2))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A3UzTFUFOMZ0"
   },
   "outputs": [],
   "source": [
    "a_add = tf.expand_dims(a, axis=2)#we are adding an additional axis at 2nd dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fc4R99CxOMZ2",
    "outputId": "fbb6308d-198b-4437-af9d-1afb3d2c6b72"
   },
   "outputs": [],
   "source": [
    "a_add.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQayeY4wOMZ5"
   },
   "source": [
    "## 1.6 Squeezing dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVomMzI6OMZ6"
   },
   "source": [
    "<pre>\n",
    "Note that we can squeeze along with the axis with shape 1\n",
    "\n",
    "Ex: \n",
    "A.shape= [3,4,1] ==> we can squeez it on axis=2 will give [3,4]\n",
    "A.shape= [3,1,4] ==> we can squeez it on axis=1 will give [3,4]\n",
    "A.shape= [1,3,4] ==> we can squeez it on axis=0 will give [3,4]\n",
    "A.shape= [2,3,4] ==> we can't squeez it on any of the axis\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FYqN12oiOMZ9",
    "outputId": "18ea673d-f869-4d7a-e369-4bcc976cde32"
   },
   "outputs": [],
   "source": [
    "a = tf.random.uniform(shape=(3,1,4))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-H6UcJfJOMaA"
   },
   "outputs": [],
   "source": [
    "a_squ = tf.squeeze(a, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RTxBvofpOMaD",
    "outputId": "60a18069-76fd-405a-97e2-47962e7555f1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a_squ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_SArBwQROMaE"
   },
   "source": [
    "## 1.7 Reshaping of tensors\n",
    "\n",
    "<a href='https://www.tensorflow.org/api_docs/python/tf/reshape'> check the documentation </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "wEjdOLJROMaF",
    "outputId": "19bf779c-fe88-4a85-9891-81647f90a99b"
   },
   "outputs": [],
   "source": [
    "a = tf.random.uniform(shape=(5,3,4))\n",
    "\n",
    "# tf.reshape(tensor, [reshape dimensions]])\n",
    "b = tf.reshape(a, [a.shape[0]*a.shape[1],a.shape[2]])\n",
    "\n",
    "print(a.shape, b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USHug53cOMaI"
   },
   "source": [
    "# 2. Call Backs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pYFub-clOMaJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Edk77ekZOMaM"
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "# if you observe the input shape its 3 dimensional vector\n",
    "# for each image we have a (28*28) vector\n",
    "# we will convert the (28*28) vector into single dimensional vector of 1 * 784 \n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2]) \n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1]*X_test.shape[2]) \n",
    "Y_train = tf.keras.utils.to_categorical(y_train, 10) \n",
    "Y_test = tf.keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9zuUwtN0OMaO",
    "outputId": "e67c5a2d-a1ae-4520-91b3-4dfe41adfb46"
   },
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U6sg7WeVOMaP"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense,Input,Activation\n",
    "from tensorflow.keras.models import Model\n",
    "import random as rn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_psPfAhOMaR"
   },
   "source": [
    "## 2.1 Writing custom call backs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N2zS015yOMaR"
   },
   "source": [
    "<pre>In Keras, Callback is a python class meant to be subclassed to provide specific functionality, <br> with a set of methods called at various stages of training (including batch/epoch start and ends), <br> testing, and predicting. Callbacks are useful to get a view on internal states and statistics of the model during training</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Up_jqqGfOMaS"
   },
   "source": [
    "<pre>\n",
    "<b>Writing Call Backs</b> - You can inherit from <b>`tf.keras.callbacks.Callback`</b>,<br> Copied the code for callback class from tensorflow documentation and pased in below cell, you can check that code. <br>It has many methods like batch/epoch_begin/end. so you can do manipulate the model parameters or <br>print the required outputs using these methods.<br> The `logs` dict contains the loss value, and all the metrics at the end of a batch or epoch\n",
    "\n",
    "</pre>\n",
    "> <a href='https://www.w3schools.com/python/python_inheritance.asp'> Do Read this Blog to understand how to inhert other classes </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cv88yZ_pOMaT"
   },
   "outputs": [],
   "source": [
    "class Callback(object):\n",
    "    \n",
    "    \"\"\"Abstract base class used to build new callbacks.\n",
    "      Attributes:\n",
    "          params: dict. Training parameters\n",
    "              (eg. verbosity, batch size, number of epochs...).\n",
    "          model: instance of `keras.models.Model`.\n",
    "              Reference of the model being trained.\n",
    "          validation_data: Deprecated. Do not use.\n",
    "      The `logs` dictionary that callback methods\n",
    "      take as argument will contain keys for quantities relevant to\n",
    "      the current batch or epoch.\n",
    "      Currently, the `.fit()` method of the `Model` class\n",
    "      will include the following quantities in the `logs` that\n",
    "      it passes to its callbacks:\n",
    "          on_epoch_end: logs include `acc` and `loss`, and\n",
    "          optionally include `val_loss`\n",
    "          (if validation is enabled in `fit`), and `val_acc`\n",
    "          (if validation and accuracy monitoring are enabled).\n",
    "          on_batch_begin: logs include `size`,\n",
    "          the number of samples in the current batch.\n",
    "          on_batch_end: logs include `loss`, and optionally `acc`\n",
    "            (if accuracy monitoring is enabled).\n",
    "      \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.validation_data = None\n",
    "        self.model = None\n",
    "        # Whether this Callback should only run on the chief worker in a\n",
    "        # Multi-Worker setting.\n",
    "        # TODO(omalleyt): Make this attr public once solution is stable.\n",
    "        self._chief_worker_only = None\n",
    "\n",
    "    def set_params(self, params):\n",
    "        self.params = params\n",
    "\n",
    "    def set_model(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        \"\"\"A backwards compatibility alias for `on_train_batch_begin`.\"\"\"\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        \"\"\"A backwards compatibility alias for `on_train_batch_end`.\"\"\"\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        \"\"\"Called at the start of an epoch.\n",
    "        Subclasses should override for any actions to run. This function should only\n",
    "        be called during TRAIN mode.\n",
    "        Arguments:\n",
    "            epoch: integer, index of epoch.\n",
    "            logs: dict. Currently no data is passed to this argument for this method\n",
    "              but that may change in the future.\n",
    "        \"\"\"\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \"\"\"Called at the end of an epoch.\n",
    "        Subclasses should override for any actions to run. This function should only\n",
    "        be called during TRAIN mode.\n",
    "        Arguments:\n",
    "            epoch: integer, index of epoch.\n",
    "            logs: dict, metric results for this training epoch, and for the\n",
    "              validation epoch if validation is performed. Validation result keys\n",
    "              are prefixed with `val_`.\n",
    "        \"\"\"\n",
    "\n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        \"\"\"Called at the beginning of a training batch in `fit` methods.\n",
    "        Subclasses should override for any actions to run.\n",
    "        Arguments:\n",
    "            batch: integer, index of batch within the current epoch.\n",
    "            logs: dict. Has keys `batch` and `size` representing the current batch\n",
    "              number and the size of the batch.\n",
    "        \"\"\"\n",
    "        # For backwards compatibility.\n",
    "        self.on_batch_begin(batch, logs=logs)\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        \"\"\"Called at the end of a training batch in `fit` methods.\n",
    "        Subclasses should override for any actions to run.\n",
    "        Arguments:\n",
    "            batch: integer, index of batch within the current epoch.\n",
    "            logs: dict. Metric results for this batch.\n",
    "        \"\"\"\n",
    "        # For backwards compatibility.\n",
    "        self.on_batch_end(batch, logs=logs)\n",
    "\n",
    "    def on_test_batch_begin(self, batch, logs=None):\n",
    "        \"\"\"Called at the beginning of a batch in `evaluate` methods.\n",
    "        Also called at the beginning of a validation batch in the `fit`\n",
    "        methods, if validation data is provided.\n",
    "        Subclasses should override for any actions to run.\n",
    "        Arguments:\n",
    "            batch: integer, index of batch within the current epoch.\n",
    "            logs: dict. Has keys `batch` and `size` representing the current batch\n",
    "                  number and the size of the batch.\n",
    "        \"\"\"\n",
    "\n",
    "    def on_test_batch_end(self, batch, logs=None):\n",
    "        \"\"\"Called at the end of a batch in `evaluate` methods.\n",
    "        Also called at the end of a validation batch in the `fit`\n",
    "        methods, if validation data is provided.\n",
    "        Subclasses should override for any actions to run.\n",
    "        Arguments:\n",
    "            batch: integer, index of batch within the current epoch.\n",
    "            logs: dict. Metric results for this batch.\n",
    "        \"\"\"\n",
    "\n",
    "    def on_predict_batch_begin(self, batch, logs=None):\n",
    "        \"\"\"Called at the beginning of a batch in `predict` methods.\n",
    "        Subclasses should override for any actions to run.\n",
    "        Arguments:\n",
    "            batch: integer, index of batch within the current epoch.\n",
    "            logs: dict. Has keys `batch` and `size` representing the current batch\n",
    "                  number and the size of the batch.\n",
    "        \"\"\"\n",
    "\n",
    "    def on_predict_batch_end(self, batch, logs=None):\n",
    "        \"\"\"Called at the end of a batch in `predict` methods.\n",
    "        Subclasses should override for any actions to run.\n",
    "        Arguments:\n",
    "            batch: integer, index of batch within the current epoch.\n",
    "            logs: dict. Metric results for this batch.\n",
    "        \"\"\"\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        \"\"\"Called at the beginning of training.\n",
    "        Subclasses should override for any actions to run.\n",
    "        Arguments:\n",
    "            logs: dict. Currently no data is passed to this argument for this method\n",
    "                  but that may change in the future.\n",
    "        \"\"\"\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        \"\"\"Called at the end of training.\n",
    "        Subclasses should override for any actions to run.\n",
    "        Arguments:\n",
    "            logs: dict. Currently no data is passed to this argument for this method\n",
    "                  but that may change in the future.\n",
    "        \"\"\"\n",
    "\n",
    "    def on_test_begin(self, logs=None):\n",
    "        \"\"\"Called at the beginning of evaluation or validation.\n",
    "        Subclasses should override for any actions to run.\n",
    "        Arguments:\n",
    "            logs: dict. Currently no data is passed to this argument for this method\n",
    "              but that may change in the future.\n",
    "        \"\"\"\n",
    "\n",
    "    def on_test_end(self, logs=None):\n",
    "        \"\"\"Called at the end of evaluation or validation.\n",
    "        Subclasses should override for any actions to run.\n",
    "        Arguments:\n",
    "            logs: dict. Currently no data is passed to this argument for this method\n",
    "              but that may change in the future.\n",
    "        \"\"\"\n",
    "\n",
    "    def on_predict_begin(self, logs=None):\n",
    "        \"\"\"Called at the beginning of prediction.\n",
    "        Subclasses should override for any actions to run.\n",
    "        Arguments:\n",
    "            logs: dict. Currently no data is passed to this argument for this method\n",
    "              but that may change in the future.\n",
    "        \"\"\"\n",
    "\n",
    "    def on_predict_end(self, logs=None):\n",
    "        \"\"\"Called at the end of prediction.\n",
    "        Subclasses should override for any actions to run.\n",
    "        Arguments:\n",
    "            logs: dict. Currently no data is passed to this argument for this method\n",
    "              but that may change in the future.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AuQAcJeJndjD"
   },
   "source": [
    "# <font color='red'> 2.1.1 Custom callbacks for performace metrices </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pfZUPJ01OMah"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "class LossHistory(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,validation_data):\n",
    "      self.x_test = validation_data[0]\n",
    "      self.y_test= validation_data[1]\n",
    "    def on_train_begin(self, logs={}):\n",
    "        ## on begin of training, we are creating a instance varible called history\n",
    "        ## it is a dict with keys [loss, acc, val_loss, val_acc]\n",
    "        self.history={'loss': [],'accuracy': [],'val_loss': [],'val_accuracy': [],'val_recall': []}\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        true_positives=0\n",
    "        ## on end of each epoch, we will get logs and update the self.history dict\n",
    "        self.history['loss'].append(logs.get('loss'))\n",
    "        self.history['accuracy'].append(logs.get('accuracy'))\n",
    "      \n",
    "        if logs.get('val_loss', -1) != -1:\n",
    "            self.history['val_loss'].append(logs.get('val_loss'))\n",
    "        if logs.get('val_accuracy', -1) != -1:\n",
    "            self.history['val_accuracy'].append(logs.get('val_accuracy'))\n",
    "        # we can get a list of all predicted values at the end of the epoch\n",
    "        # we can use these predicted value and the true values to calculate any custom evaluation score if it is needed for our model\n",
    "        # Here we are taking log of all true positives and then taking average of it\n",
    "        y_pred= self.model.predict(self.x_test)\n",
    "        y_label_pred=np.argmax(y_pred,axis=1)\n",
    "        custom_score = np.log(np.sum(y_test== y_label_pred))/len(y_test)\n",
    "        \n",
    "        #we can also calcualte predefined metrics such as precison, recall, etc. using callbacks \n",
    "        recall = recall_score(y_test,y_label_pred,average='micro')\n",
    "        self.history['val_recall'].append(recall)\n",
    "        print('custom_Score: ',np.round(custom_score,5),'Recall: ',recall)\n",
    "            \n",
    "history_own=LossHistory(validation_data=[X_test,y_test])            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UzEyvZg-OMaj"
   },
   "source": [
    "> in the above function we have written logs={}, which means the logs is a dictionary and the keys present will the same values that gets printed while you train your model i.e model.fit()\n",
    "<img src='https://i.imgur.com/fAiHfe7.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ca3J3ySeOMak",
    "outputId": "6b66a7b5-08e0-47b3-fc30-8e9e4f7bfec2"
   },
   "outputs": [],
   "source": [
    "#Input layer\n",
    "input_layer = Input(shape=(784,))\n",
    "#Dense hidden layer\n",
    "layer1 = Dense(50,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n",
    "#output layer\n",
    "output = Dense(10,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer1)\n",
    "#Creating a model\n",
    "model = Model(inputs=input_layer,outputs=output)\n",
    "\n",
    "\n",
    "#Callbacks\n",
    "history_own=LossHistory(validation_data=[X_test,y_test])            \n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(0.01)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train,Y_train,epochs=3, validation_data=(X_test,Y_test), batch_size=16, callbacks=[history_own])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5nzuF0OPOMam",
    "outputId": "b5f8b177-62c9-4cd6-c97a-a1cc217b41f8"
   },
   "outputs": [],
   "source": [
    "history_own.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "riBZE6ZrOMao"
   },
   "source": [
    "# <font color='red'> 2.1.2 Writing the call back to terminate training if loss is 'NaN'</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cMYmZMVeOMap"
   },
   "outputs": [],
   "source": [
    "class TerminateNaN(tf.keras.callbacks.Callback):\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        loss = logs.get('loss')\n",
    "        if loss is not None:\n",
    "            if np.isnan(loss) or np.isinf(loss):\n",
    "                print(\"Invalid loss and terminated at epoch {}\".format(epoch))\n",
    "                self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vh4umPy9OMaq"
   },
   "source": [
    "# <font color='red'> 2.2 Using tensorflow call backs </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qv9epZaHOMaq"
   },
   "source": [
    "There are some callbacks which are implemented in the Tensorflow\n",
    "\n",
    "## <b> 2.2.1 ModelCheckpoint</b> - Save the model after every epoch. You can check documentation <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint\">here</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OvIlgI2ROMas"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h3-DSrb2OMau",
    "outputId": "c475d2e4-ba80-484f-d787-684bd80c5ecf"
   },
   "outputs": [],
   "source": [
    "#Input layer\n",
    "input_layer = Input(shape=(784,))\n",
    "#Dense hidden layer\n",
    "layer1 = Dense(50,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n",
    "#output layer\n",
    "output = Dense(10,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer1)\n",
    "#Creating a model\n",
    "model = Model(inputs=input_layer,outputs=output)\n",
    "\n",
    "\n",
    "#Callbacks\n",
    "#file path, it saves the model in the 'model_save' folder and we are naming model with epoch number \n",
    "#and val acc to differtiate with other models\n",
    "#you have to create model_save folder before running the code.\n",
    "filepath=\"model_save/weights-{epoch:02d}-{val_accuracy:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss',  verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(0.01)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train,Y_train,epochs=5,validation_data=(X_test,Y_test),batch_size=16,callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GfAHPmifOMax"
   },
   "source": [
    "<pre>If you need 4th epoch model, you can load that model as below. It saves optimizer state as well. so noo need to recompile. </pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416
    },
    "id": "r0AIY28BOMaz",
    "outputId": "a1c43497-780e-4976-9303-8b36c07c59a9"
   },
   "outputs": [],
   "source": [
    "model.load_weights('model_save/weights-04-0.7914.hdf5')#change this with your name which you got in above output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lJ7A1PJHOMa0"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yrHJBrPCOMa3"
   },
   "source": [
    "## 2.2.2 EarlyStopping:\n",
    "\n",
    "<pre>Stop training when a monitored quantity has stopped improving. You can check the documentatin <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping\">here</a></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FS1jubUuOMa3"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_BxU-droOMa6",
    "outputId": "579193f7-69c5-4a8d-b5e5-7310f57d870d"
   },
   "outputs": [],
   "source": [
    "#Input layer\n",
    "input_layer = Input(shape=(784,))\n",
    "#Dense hidden layer\n",
    "layer1 = Dense(50,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n",
    "#output layer\n",
    "output = Dense(10,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer1)\n",
    "#Creating a model\n",
    "model = Model(inputs=input_layer,outputs=output)\n",
    "\n",
    "#you can monitor any quantity (here i am monitoring val_loss), you can give any number for patience based on your need. \n",
    "#i am terminating training if my validation loss incresing at once than previous loss. so maintained 1. you can give min delta\n",
    "#an absolute change of less than min_delta, will count as no improvement. i maintained 0.35 because i don't want to run \n",
    "#so many epoch to see termination\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.35, patience=1, verbose=1)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(0.01)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train,Y_train,epochs=10,validation_data=(X_test,Y_test),batch_size=16,callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05WyP1W2OMa9"
   },
   "source": [
    "<pre>It stopped at 2nd epoch only. You can use this early stopping to get best model than overfitted model</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AjQJADh8OMa-"
   },
   "source": [
    "## 2.2.3 LearningRateScheduler:\n",
    "<pre>You can schedule learning rate for every epoch. You can decrease or increase the learning rate based on epoch number. </pre> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "er-L_eZIOMa_"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3YONlCwyOMbA"
   },
   "outputs": [],
   "source": [
    "def changeLearningRate(epoch):\n",
    "    #here we are performing exponential decay of the learning rate\n",
    "    initial_learningrate=0.1\n",
    "    changed = initial_learningrate*(1-0.1)**epoch\n",
    "    return changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hS18HNhtOMbC"
   },
   "outputs": [],
   "source": [
    "changed_lr = []\n",
    "for i in range(1,50):\n",
    "    changed_lr.append(changeLearningRate(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T7JjoQ2aOMbE"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PSdopgjfOMbG"
   },
   "outputs": [],
   "source": [
    "plt.plot(changed_lr)\n",
    "plt.ylabel('learning_rate')\n",
    "plt.xlabel('epoch number')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YSvB3InnOMbH"
   },
   "source": [
    "If you check above figure, learning rate is decreasing if my epoch number is increasing. We are using same function to schedule our learning rate based on epoch number. You can write your own function or you can write custom call back to decrease the learning rate based on val_loss/acc. \n",
    "In the above function, we have implemented exponential decay with decay rate 0.1, you can check that <a href=\"https://mathbitsnotebook.com/Algebra2/Exponential/EXGrowthDecay.html\">here</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vTZCQXQ_OMbH"
   },
   "outputs": [],
   "source": [
    "#Input layer\n",
    "input_layer = Input(shape=(784,))\n",
    "#Dense hidden layer\n",
    "layer1 = Dense(50,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n",
    "#output layer\n",
    "output = Dense(10,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer1)\n",
    "#Creating a model\n",
    "model = Model(inputs=input_layer,outputs=output)\n",
    "\n",
    "lrschedule = LearningRateScheduler(changeLearningRate, verbose=1)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.1),\n",
    "              loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train,Y_train,epochs=3,validation_data=(X_test,Y_test),batch_size=16,callbacks=[lrschedule])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fVm_fKElOMbK"
   },
   "source": [
    "## 2.2.4 ReduceLROnPlateau\n",
    "It is similar to EarlyStopping, you can reduce your Learning rate by some factor if my val_loss/acc is not improving. You can check the documentation <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ReduceLROnPlateau\">here</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V35jamIuOMbL"
   },
   "source": [
    "<pre>There are many pre built call backs are available in Tensorflow, you can check those in <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/callbacks\">this</a> link.\n",
    "\n",
    "You can give as many callbacks you want while training the model as given below.</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ts8yx-dwOMbO"
   },
   "outputs": [],
   "source": [
    "#Input layer\n",
    "input_layer = Input(shape=(784,))\n",
    "#Dense hidden layer\n",
    "layer1 = Dense(50,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=30))(input_layer)\n",
    "#output layer\n",
    "output = Dense(10,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0))(layer1)\n",
    "#Creating a model\n",
    "model = Model(inputs=input_layer,outputs=output)\n",
    "\n",
    "#create a call back list\n",
    "lrschedule = LearningRateScheduler(changeLearningRate, verbose=0.1)\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.25, patience=1, verbose=1)\n",
    "filepath=\"model_save/weights-{epoch:02d}-{val_accuracy:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='auto')\n",
    "\n",
    "\n",
    "# here we are creating a list with all the callbacks we want\n",
    "callback_list = [lrschedule, earlystop, checkpoint]\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.1),\n",
    "              loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train,Y_train,epochs=5,validation_data=(X_test,Y_test),batch_size=16,callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k03l4h9Q55PI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "0fjRvsmIOMYG",
    "vhFWsCP1OMY0",
    "_galZ10JOMZX",
    "luaCDJ_8OMZY",
    "z8dLCOEaOMZj",
    "OQayeY4wOMZ5",
    "_SArBwQROMaE"
   ],
   "name": "Call_Backs_Reference.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
